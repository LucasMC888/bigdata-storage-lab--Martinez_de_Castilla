# De CSVs heterog√©neos a un almac√©n anal√≠tico confiable  
Repositorio: `bigdata-storage-lab-<apellido>`

---

## üéØ Objetivo del laboratorio
El prop√≥sito de este laboratorio es dise√±ar y ejecutar un flujo de procesamiento de datos que permita transformar **archivos CSV heterog√©neos** en un **almac√©n anal√≠tico confiable**, siguiendo buenas pr√°cticas de ingenier√≠a de datos:

1. **Ingesta**: recepci√≥n y almacenamiento inicial de archivos CSV de distintas fuentes y formatos.  
2. **Validaci√≥n**: controles b√°sicos (tipos de datos, duplicados, valores nulos, reglas de negocio m√≠nimas).  
3. **Normalizaci√≥n**: unificaci√≥n de esquemas, estandarizaci√≥n de nombres de columnas, tipos y formatos.  
4. **Persistencia en capas**:  
   - **Bronze**: datos crudos validados.  
   - **Silver**: datos normalizados y listos para an√°lisis.  
5. **Exposici√≥n de KPIs**: construcci√≥n de m√©tricas agregadas y visualizaci√≥n con una app en **Streamlit**.

---

## üì¶ Entregables
- **Repositorio GitHub p√∫blico** con:
  - C√≥digo fuente (scripts/notebooks/pipelines).  
  - Definici√≥n del modelo de datos (diccionario de datos o esquema).  
  - Documentaci√≥n clara en Markdown.  
- **Aplicaci√≥n Streamlit** publicada (ej. en Streamlit Cloud o similar) que muestre los KPIs principales y el flujo de trabajo.

---

## ‚úÖ Criterios de evaluaci√≥n
1. **Dise√±o y justificaci√≥n t√©cnica**  
   - Elecci√≥n de librer√≠as/herramientas y explicaci√≥n de decisiones.  
   - Claridad en la arquitectura de ingesta‚Äìprocesamiento‚Äìalmacenamiento.  

2. **Calidad de datos**  
   - Validaciones implementadas.  
   - Manejo expl√≠cito de inconsistencias.  

3. **Trazabilidad y dise√±o de DW**  
   - Organizaci√≥n de capas **bronze/silver**.  
   - Evidencia de lineage o comentarios que permitan seguir el rastro de los datos.  

4. **Documentaci√≥n**  
   - README y diagramas claros.  
   - Instrucciones reproducibles para ejecutar el laboratorio.  

---

## üö´ Qu√© NO subir
- Datos sensibles, personales o confidenciales.  
- Archivos CSV con informaci√≥n propietaria.  
- Credenciales (tokens, claves, contrase√±as).  
- Dumps de bases de datos reales.  

En su lugar, utilice **datasets sint√©ticos o p√∫blicos** (ej. Kaggle, data.gov, OpenData).

---

## ‚è±Ô∏è Tiempo estimado por fase
- **Ingesta de CSVs** ‚Üí 2 h  
- **Validaci√≥n y limpieza** ‚Üí 3 h  
- **Normalizaci√≥n y modelado en capas (bronze/silver)** ‚Üí 4 h  
- **Generaci√≥n de KPIs y exposici√≥n en Streamlit** ‚Üí 3 h  
- **Documentaci√≥n y entrega en GitHub** ‚Üí 2 h  

**Total estimado:** ~14 horas de trabajo.

---

## üìù Notas finales
Este laboratorio busca emular un escenario real de **data engineering** donde la trazabilidad y la confianza en los datos son tan importantes como la implementaci√≥n t√©cnica.  
